{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Imports (takes 4-5s)\nimport cv2\nimport numpy as np\nimport os\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2gray\n\nfrom skimage import measure\nfrom skimage import data, img_as_float\nfrom skimage import exposure\nfrom skimage import filters\n\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport plotly.express as px",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "192"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#========= Sources\n#CHMI: https://www.chmi.cz/files/portal/docs/meteo/kam/ , last access: 20 February 2023;\n#University of Utah: https://home.chpc.utah.edu/~u0553130/Camera_Display/wbbs.html, last access: 20 February 2023;\n#DWD: https://opendata.dwd.de/weather/webcam/Offenbach-W/, last access: 20 February 2023;",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def showfcmap(figname,cmap='viridis'):\n    # Shows picture in the colormap\n    plt.figure(figsize = (20,20))\n    plt.imshow(figname,cmap=cmap)\n    plt.show()\n\ndef showf(figname):\n    # Shows figure\n    plt.figure(figsize = (20,20))\n    plt.imshow(figname)\n    plt.show()\n\ndef cut_point_CHMI(path_f,u=0,d=100000,l=0,r=100000):\n    #preprocesses image and crops to the object defined by u,d,l,r\n    im_t = cv2.imread(path_f)\n    img = rgb2gray(im_t)\n\n    #Setting the points for cropped image - cuts name, time and text( for CHMI cameras img[180::,0::])\n    cropped = img[180::,0::]\n    cropped = exposure.rescale_intensity(img)\n    gamma_corrected = exposure.adjust_gamma(cropped, 0.6)\n    edge_sobel = filters.sobel(gamma_corrected)\n    house = edge_sobel[u:d,l:r]\n    return img\n\ndef show_val_px(path):\n    #shows picture in plotly.express - tooltiptext with pixel position\n    original = cv2.imread(path)\n    fig = px.imshow(original)\n    fig.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "directory = './IMG'\n \n# iterate over files in  that directory\n#====== zentralbank 1502,1705,1997,2099\n#====== Commerzbank 1549,1699,1935,1985\nB = [1549,1699,1935,1985]\n\n# For values where all obsect were not visible these were named 'FG',\n# others training were named OK, or ON - for \"Ok Night\"\n# You can use different approach placing training set into different directories,etc.\n\ndata = []\nlabels = []\nfor filename in os.listdir(directory):\n    f = os.path.join(directory, filename)\n    #print(f)\n    if 'ON' in filename:\n        im = cut_point(f,B)\n        labels.append('N')\n        data.append(im)\n    elif 'FG' in filename:\n        im = cut_point(f,B)\n        labels.append('FG')\n        data.append(im)\n    elif 'OK' in filename:\n        im = cut_point(f,B)\n        labels.append('OK')\n        data.append(im)\n    elif 'OK3' in filename:\n        im = cut_point(f,B)\n        labels.append('OK')\n        data.append(im)\n    #showf(im)\n\nmodel = KNeighborsClassifier(n_neighbors=1)\n\n# encode the labels as integers\nle = preprocessing.LabelEncoder()\nlabels = le.fit_transform(labels)\n\nlabels = np.asarray(labels)\ndata = np.asarray(data)\n\n# reshape data from 3 to  dims\nnsamples, nx, ny = data.shape\nd2_train_dataset = data.reshape((nsamples,nx*ny))\n\n#train KNN,\nknnc = model.fit(d2_train_dataset, labels)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#@title Testing predictions\n\n# assign directory\ndirectory = '/content/IMG'\n \n# iterate over files in  that directory, skip if they were used in training\n# this could be shortened, but it was kept for future use (different filenames, ect)\ndataT = []\nlabels = []\nfnames = []\nfor filename in os.listdir(directory):\n    try:\n        f = os.path.join(directory, filename)\n        print(f)\n        if 'FG' in filename:\n            continue\n        elif 'OK' in filename:\n            continue\n        elif 'ON' in filename:\n            continue\n        elif 'OK3' in filename:\n            continue\n        else:\n            im = cut_point(f,B)\n        dataT.append(im)\n        fnames.append(filename)\n      #print(filename)\n      #showf(im)\n    except Exception as e:\n        print(e)\n        print(filename)\n\ndataT = np.asarray(dataT)\n\n# reshape data from 3 to  dims\nnsamples, nx, ny = dataT.shape\nd2_test_dataset = dataT.reshape((nsamples,nx*ny))\n\nvysl = []\nfor id,z in enumerate(d2_test_dataset):\n    pred= knnc.predict(z.reshape(1, -1))\n    vysl.append(pred)\n    print(pred, fnames[id])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Read values from label encoding\npredic_decoded = list(le.inverse_transform(vysl))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#@title Save models\nimport pickle \n\n# Define list of models (somethong like knn, clf...) \n# Save it in the loop, if there are multiple of them \n\nmodels = [knnc_mtn_tops,knnc_mtn_tops2,knnc_mtn_back,knnc_mountains,knnc_building,knnc_stadium ]\nfor ind,val in enumerate(models):\n    nam = str(ind)\n    knnPickle = open(f'/content/knnpickle{nam}_Ffile', 'wb') \n    # source, destination \n    pickle.dump(val, knnPickle)  \n    # close the file\n    knnPickle.close()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}